#!/usr/bin/env python3
"""
Investigate violations output by displaying random parquet rows with their annotations.

This script displays a random parquet row text along with the parsed violation annotations.
It can filter by category:
- sir: Special Investigation Reports only (default)
- noviolation: Documents with 0 violations
- violation: Documents with 1-9 violations
- manyviolation: Documents with 10+ violations
"""

import argparse
import ast
import logging
import random
import sys
from pathlib import Path
from typing import Dict, List, Optional

import pandas as pd

# Set up logger
logger = logging.getLogger(__name__)


def load_violations_csv(csv_path: str) -> pd.DataFrame:
    """Load violations CSV file."""
    logger.info(f"Loading violations CSV from: {csv_path}")
    df = pd.read_csv(csv_path)
    logger.info(f"Loaded {len(df)} records")
    logger.info(f"Records with violations: {len(df[df['num_violations'] > 0])}")
    return df


def find_document_in_parquet(sha256: str, parquet_dir: str) -> Optional[Dict]:
    """Find a document in parquet files by SHA256 hash."""
    parquet_path = Path(parquet_dir)
    parquet_files = list(parquet_path.glob("*.parquet"))
    
    for parquet_file in parquet_files:
        try:
            df = pd.read_parquet(parquet_file)
            matches = df[df['sha256'] == sha256]
            
            if not matches.empty:
                row = matches.iloc[0]
                return {
                    'sha256': row['sha256'],
                    'dateprocessed': row['dateprocessed'],
                    'text': row['text'],
                    'parquet_file': parquet_file.name
                }
        except Exception as e:
            logger.error(f"Error reading {parquet_file.name}: {e}")
            continue
    
    return None


def display_document(violation_record: Dict, original_doc: Dict) -> None:
    """Display a document's text and annotation."""
    print("\n" + "="*80)
    print("RANDOM DOCUMENT SAMPLE")
    print("="*80)

    print("\n--- ANNOTATION ---")
    print(f"SHA256: {violation_record['sha256']}")
    print(f"Agency ID: {violation_record['agency_id']}")
    print(f"Agency Name: {violation_record['agency_name']}")
    print(f"Document Title: {violation_record.get('document_title', 'N/A')}")
    print(f"Date: {violation_record['date']}")
    print(f"Special Investigation Report: {'Yes' if violation_record.get('is_special_investigation') else 'No'}")
    print(f"Number of Violations: {violation_record['num_violations']}")
    if violation_record['violations_list'] and not pd.isna(violation_record['violations_list']):
        violations = violation_record['violations_list'].split('; ')
        print(f"Violations:")
        for i, violation in enumerate(violations, 1):
            print(f"  {i}. {violation}")
    else:
        print("Violations: None")
    
    if original_doc:
        print(f"\nParquet File: {original_doc['parquet_file']}")
        print(f"Date Processed: {original_doc['dateprocessed']}")
        
        # Parse text
        try:
            # Handle both string and array formats
            text_data = original_doc['text']
            if isinstance(text_data, str):
                # Parse string representation safely
                # Note: parquet files generated by this pipeline are trusted
                text_pages = ast.literal_eval(text_data)
            else:
                # It's already an array (numpy array or list)
                text_pages = list(text_data)
            
            # Display full text
            full_text = '\n'.join(text_pages)
            print(f"\n--- DOCUMENT TEXT ({len(text_pages)} pages, {len(full_text)} chars) ---")
            print(full_text)
            
        except Exception as e:
            logger.error(f"Error parsing text: {e}")
            print(f"\n✗ ERROR parsing text: {e}")
    else:
        print("\n✗ Original document NOT FOUND in parquet files [ERROR]")
    
    print("\n" + "="*80)


def show_random_document(violations_csv: str, parquet_dir: str, category: str = "sir") -> None:
    """Show a random document from the specified category."""
    # Load violations CSV
    logger.info(f"Loading violations CSV from: {violations_csv}")
    df = pd.read_csv(violations_csv)
    logger.info(f"Loaded {len(df)} records")

    # Filter by category
    if category == "sir":
        filtered_df = df[df['is_special_investigation'] == True]
        category_name = "Special Investigation Reports"
    elif category == "noviolation":
        filtered_df = df[df['num_violations'] == 0]
        category_name = "no violations"
    elif category == "violation":
        filtered_df = df[(df['num_violations'] >= 1) & (df['num_violations'] < 10)]
        category_name = "1-9 violations"
    elif category == "manyviolation":
        filtered_df = df[df['num_violations'] >= 10]
        category_name = "10+ violations"
    else:  # "all"
        filtered_df = df
        category_name = "all categories"

    if len(filtered_df) == 0:
        print(f"No documents found in category: {category}")
        return

    logger.info(f"Found {len(filtered_df)} documents in category '{category_name}'")

    # Select a random document
    random_row = filtered_df.sample(n=1).iloc[0]

    violation_record = {
        'sha256': random_row['sha256'],
        'agency_id': random_row['agency_id'],
        'agency_name': random_row['agency_name'],
        'document_title': random_row.get('document_title', 'N/A'),
        'date': random_row['date'],
        'is_special_investigation': random_row.get('is_special_investigation', False),
        'num_violations': random_row['num_violations'],
        'violations_list': random_row['violations_list']
    }
    
    # Find original document in parquet files
    original_doc = find_document_in_parquet(random_row['sha256'], parquet_dir)
    
    if original_doc is None:
        print(f"ERROR: Could not find document with SHA256 {random_row['sha256']} in parquet files")
        return
    
    # Display the document
    display_document(violation_record, original_doc)


def main():
    """Main entry point."""
    parser = argparse.ArgumentParser(
        description="Show a random parquet row text with its violation annotation",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Categories:
  sir            - Special Investigation Reports only (default)
  noviolation    - Documents with 0 violations
  violation      - Documents with 1-9 violations
  manyviolation  - Documents with 10+ violations
  all            - Any document

Examples:
  # Show a random Special Investigation Report (default)
  python3 investigate_violations.py

  # Show a random document with no violations
  python3 investigate_violations.py --category noviolation

  # Show a random document with many violations
  python3 investigate_violations.py --category manyviolation

  # Show a random document with 1-9 violations
  python3 investigate_violations.py --category violation

  # Show any document regardless of type
  python3 investigate_violations.py --category all
        """
    )
    parser.add_argument(
        "--violations-csv",
        default="../violations_output.csv",
        help="Path to violations CSV file (default: ../violations_output.csv)"
    )
    parser.add_argument(
        "--parquet-dir",
        default="parquet_files",
        help="Directory containing parquet files (default: parquet_files)"
    )
    parser.add_argument(
        "--category",
        choices=["sir", "noviolation", "violation", "manyviolation", "all"],
        default="sir",
        help="Category of documents to show (default: sir)"
    )
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose debug output"
    )
    
    args = parser.parse_args()
    
    # Configure logging
    logging.basicConfig(
        level=logging.DEBUG if args.verbose else logging.INFO,
        format='%(asctime)s - %(levelname)s - %(message)s'
    )
    
    # Check if files exist
    if not Path(args.violations_csv).exists():
        logger.error(f"Violations CSV not found: {args.violations_csv}")
        logger.info("Run: python3 pdf_parsing/parse_parquet_violations.py --parquet-dir pdf_parsing/parquet_files -o violations_output.csv")
        sys.exit(1)
    
    if not Path(args.parquet_dir).exists():
        logger.error(f"Parquet directory not found: {args.parquet_dir}")
        sys.exit(1)
    
    show_random_document(args.violations_csv, args.parquet_dir, args.category)


if __name__ == "__main__":
    main()
